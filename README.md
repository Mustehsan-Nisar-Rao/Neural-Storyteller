# ğŸ§  Neural Storyteller â€“ Image Captioning using Seq2Seq

Neural Storyteller is a **multimodal deep learning project** that generates natural language descriptions from images using a **Sequence-to-Sequence (Seq2Seq)** architecture. The project integrates **Computer Vision** and **Natural Language Processing** to build an end-to-end image captioning system.

---

## ğŸš€ Features

âœ… Image caption generation using Deep Learning
âœ… Pre-trained ResNet50 feature extraction
âœ… Encoderâ€“Decoder Seq2Seq architecture
âœ… Greedy Search caption generation
âœ… Beam Search caption generation
âœ… BLEU, METEOR, Precision, Recall, and F1 evaluation
âœ… Interactive Gradio Web App
âœ… Training and validation visualization

---

## ğŸ“‚ Dataset

The model is trained using the **Flickr30k Dataset**.

ğŸ”— Dataset Link:
[https://www.kaggle.com/datasets/adityajn105/flickr30k](https://www.kaggle.com/datasets/adityajn105/flickr30k)

### Dataset Details

* ~31,000 images
* Multiple captions per image
* Real-world scene descriptions

---

## ğŸ—ï¸ Model Architecture

### ğŸ”¹ Feature Extraction (CNN)

* Pre-trained **ResNet50**
* Fully connected classification layer removed
* Extracts **2048-dimensional feature vectors**
* Features cached for efficient training

---

### ğŸ”¹ Seq2Seq Caption Generator

#### Encoder

* Linear projection layer
* Converts 2048-dim image vector â†’ hidden size

#### Decoder

* LSTM-based sequence model
* Uses word embeddings
* Generates caption token-by-token

---

## ğŸ“Š Evaluation Metrics

The model performance is evaluated using:

* BLEU-1, BLEU-2, BLEU-3, BLEU-4
* METEOR Score
* Token-Level Precision
* Token-Level Recall
* F1 Score

---

## ğŸ–¼ï¸ Example Output

The model:

* Takes an image as input
* Generates descriptive caption
* Compares prediction with ground truth caption

---

## ğŸŒ App Deployment

The project includes a **Gradio Interface** allowing users to:

* Upload an image
* Generate captions using Greedy & Beam Search
* View evaluation metrics

---

## ğŸ› ï¸ Tech Stack

* Python
* PyTorch
* Torchvision
* NLTK
* Gradio
* NumPy
* Matplotlib

---

## ğŸ“ Project Structure

```
ğŸ“¦ Neural Storyteller
â”‚
â”œâ”€â”€ app.py                         # Gradio deployment interface
â”œâ”€â”€ model.py                       # Encoder & Decoder architecture
â”œâ”€â”€ neural-story-teller.ipynb      # Training, evaluation & experiments
â”œâ”€â”€ hf_bpe-merges.txt              # Tokenizer merges file
â”œâ”€â”€ hf_bpe-vocab.json              # Tokenizer vocabulary
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ README.md                      # Project documentation
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone Repository

```bash
https://github.com/Mustehsan-Nisar-Rao/Neural-Storyteller
cd neural-storyteller
```

---

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Run Gradio App

```bash
python app.py
```

---

## ğŸ“ˆ Training Details

| Component       | Description            |
| --------------- | ---------------------- |
| Loss Function   | CrossEntropy Loss      |
| Optimizer       | Adam                   |
| Hardware        | Kaggle GPU (T4 x2)     |
| Feature Caching | Enabled using ResNet50 |

---

## ğŸ” Inference Methods

### Greedy Search

Selects highest probability word at each step.

### Beam Search

Maintains multiple candidate sequences to generate better captions.

---

## ğŸ’¡ Key Learnings

* Multimodal Deep Learning
* Sequence-to-Sequence Models
* Image Feature Engineering
* NLP Evaluation Metrics
* AI Model Deployment

---

## ğŸ”® Future Improvements

* Transformer-based Caption Models
* Attention Mechanism Integration
* CIDEr & ROUGE Evaluation
* HuggingFace Spaces Deployment
* Real-time Video Captioning

---

## ğŸ‘¨â€ğŸ’» Author

**Mustehsan Nisar Rao**
Computer Science Student
AI & Full Stack Development Enthusiast

---

## â­ Acknowledgements

* Flickr30k Dataset Contributors
* PyTorch Community
* Kaggle GPU Resources

